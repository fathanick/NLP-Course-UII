{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['this is the first document',\n",
    "          'this is the second document or second sentence',\n",
    "          'and this is the third one',\n",
    "          'is this the first document or document one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "#instantiate CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 10)\t1\n  (0, 3)\t1\n  (0, 8)\t1\n  (0, 2)\t1\n  (0, 1)\t1\n  (1, 10)\t1\n  (1, 3)\t1\n  (1, 8)\t1\n  (1, 1)\t1\n  (1, 6)\t2\n  (1, 5)\t1\n  (1, 7)\t1\n  (2, 10)\t1\n  (2, 3)\t1\n  (2, 8)\t1\n  (2, 0)\t1\n  (2, 9)\t1\n  (2, 4)\t1\n  (3, 10)\t1\n  (3, 3)\t1\n  (3, 8)\t1\n  (3, 2)\t1\n  (3, 1)\t2\n  (3, 5)\t1\n  (3, 4)\t1\n"
     ]
    }
   ],
   "source": [
    "#generate word counts\n",
    "word_count_vect = cv.fit_transform(corpus)\n",
    "#view non-zero feature positions in the sparse matrix\n",
    "print(word_count_vect)\n",
    "#The preceeding output represents the total count for each (x,y) pair\n",
    "# x represents a document and y represents a specific word/feature\n",
    "# the values is the number of times y occurs in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 11)\n"
     ]
    }
   ],
   "source": [
    "#shape\n",
    "print(word_count_vect.shape) #4 docs, 11 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 2, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 2, 1, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "#view dense representation\n",
    "cv_matrix = word_count_vect.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['and',\n",
       " 'document',\n",
       " 'first',\n",
       " 'is',\n",
       " 'one',\n",
       " 'or',\n",
       " 'second',\n",
       " 'sentence',\n",
       " 'the',\n",
       " 'third',\n",
       " 'this']"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "#get all unique words in the corpus\n",
    "vocab = cv.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   and  document  first  is  one  or  second  sentence  the  third  this\n",
       "0    0         1      1   1    0   0       0         0    1      0     1\n",
       "1    0         1      0   1    0   1       2         1    1      0     1\n",
       "2    1         0      0   1    1   0       0         0    1      1     1\n",
       "3    0         2      1   1    1   1       0         0    1      0     1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>and</th>\n      <th>document</th>\n      <th>first</th>\n      <th>is</th>\n      <th>one</th>\n      <th>or</th>\n      <th>second</th>\n      <th>sentence</th>\n      <th>the</th>\n      <th>third</th>\n      <th>this</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "#bag of words model based document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.38408524, 0.        ,\n",
       "        0.38408524],\n",
       "       [0.        , 0.24394892, 0.        , 0.19944423, 0.        ,\n",
       "        0.30132545, 0.76438624, 0.38219312, 0.19944423, 0.        ,\n",
       "        0.19944423],\n",
       "       [0.53927767, 0.        , 0.        , 0.28141746, 0.42517271,\n",
       "        0.        , 0.        , 0.        , 0.28141746, 0.53927767,\n",
       "        0.28141746],\n",
       "       [0.        , 0.61480604, 0.37970389, 0.25132211, 0.37970389,\n",
       "        0.37970389, 0.        , 0.        , 0.25132211, 0.        ,\n",
       "        0.25132211]])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "#TF-IDF using TfidfTransformer\n",
    "tf_idf = TfidfTransformer(use_idf=True)\n",
    "tf_idf_matrix = tf_idf.fit_transform(cv_matrix)\n",
    "tf_idf_matrix = tf_idf_matrix.toarray()\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      and  document   first      is     one      or  second  sentence     the  \\\n",
       "0  0.0000    0.4698  0.5803  0.3841  0.0000  0.0000  0.0000    0.0000  0.3841   \n",
       "1  0.0000    0.2439  0.0000  0.1994  0.0000  0.3013  0.7644    0.3822  0.1994   \n",
       "2  0.5393    0.0000  0.0000  0.2814  0.4252  0.0000  0.0000    0.0000  0.2814   \n",
       "3  0.0000    0.6148  0.3797  0.2513  0.3797  0.3797  0.0000    0.0000  0.2513   \n",
       "\n",
       "    third    this  \n",
       "0  0.0000  0.3841  \n",
       "1  0.0000  0.1994  \n",
       "2  0.5393  0.2814  \n",
       "3  0.0000  0.2513  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>and</th>\n      <th>document</th>\n      <th>first</th>\n      <th>is</th>\n      <th>one</th>\n      <th>or</th>\n      <th>second</th>\n      <th>sentence</th>\n      <th>the</th>\n      <th>third</th>\n      <th>this</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.0000</td>\n      <td>0.4698</td>\n      <td>0.5803</td>\n      <td>0.3841</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.3841</td>\n      <td>0.0000</td>\n      <td>0.3841</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.0000</td>\n      <td>0.2439</td>\n      <td>0.0000</td>\n      <td>0.1994</td>\n      <td>0.0000</td>\n      <td>0.3013</td>\n      <td>0.7644</td>\n      <td>0.3822</td>\n      <td>0.1994</td>\n      <td>0.0000</td>\n      <td>0.1994</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.5393</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2814</td>\n      <td>0.4252</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2814</td>\n      <td>0.5393</td>\n      <td>0.2814</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.0000</td>\n      <td>0.6148</td>\n      <td>0.3797</td>\n      <td>0.2513</td>\n      <td>0.3797</td>\n      <td>0.3797</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2513</td>\n      <td>0.0000</td>\n      <td>0.2513</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "pd.DataFrame(np.round(tf_idf_matrix,4), columns=vocab)"
   ]
  }
 ]
}